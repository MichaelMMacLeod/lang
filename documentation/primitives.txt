FIXME:

  1. get rid of x/y to mean WITH in some places when you said it means
     HAS SCOPE SET!

  2. Rule, Env defs?

Notation:

  1. Y/{Z} means that the scope-set of term Y is a set containing only
     one scope, Z.

  2. Y/X means that the term Y has scope-set X.

  3. Y/X+{Z} means that term Y has scope-set (X union {Z}) for some
     scope Z.

  4. 'next scope S' is a never-before-seen scope, i.e., no term has
     ever before had S in its scope-set.

  5. If an identifier is used without a scope-set (like 'X' instead of
     'X/S'), then the scope-set is meant to be inferred from the
     context. If a definition requires that a rule be placed in the
     environment then---unless stated otherwise---the enclosing
     scope-set is the top-level empty one, {}.

  6. {unique-scope} is a unique scope.

FIXME: remove the following?

 ;;; Definition of [noreduce-scope]: A single, never-before-seen
 ;;; scope. Because the only way to introduce scopes on terms is through
 ;;; 'let' and 'letrec', and because the scopes introduced by those terms
 ;;; are always never-before-seen-scopes, no term (outside of the ones
 ;;; specified here) can ever have this noreduce-scope in their
 ;;; scope-set. The purpose of the noreduce-scope is to make the term
 ;;; (no-reduce/{noreduce-scope} $) irreducible. Because it is impossible
 ;;; to apply the noreduce-scope to any term in user code, it's impossible
 ;;; to write a rule whose pattern contains
 ;;; no-reduce/{[no-reduce-scope]}. Because there is no rule specified here
 ;;; (on purpose) that makes (noreduce/{noreduce-scope} $) a fixed-point,
 ;;; or any rule that re-writes it to something reducible to one, it cannot
 ;;; be reduced to a fixed-point. Thus, if that term ever becomes a redex
 ;;; in real code, the program will crash. This is occasionally useful
 ;;; (more will be said about this later).

Definitions [env], [rule]:

  For any two terms <pattern>/PS and <result>/RS, the following creates
  a single rule ...

    (Rule <pattern> <result>)

  ... if and only if <pattern> and <result> do not contain any
  identifiers beginning with '$', or '$' itself (with no characters
  following it) ['$' may appear at the end or middle of an identifier
  with >=1 characters, but not at the beginning]. This rule is
  applicable to all terms <T>/PS+?, and, if applied, reduces to
  <result>/RS.

  For any two terms <$pattern>/PS and <$result>/RS the following
  creates an infinite set of rules ...

    (Rule <$pattern>/PS <$result>/RS+$)

  ... if and only if (for every dollar-sign-identifier D in
  <$result>/RS, D is in <$pattern>/PS).


Definition [rule$]:

    For an environment E, Let APP be a scope called the 'rule
    application scope' unique to E. Then for all terms <$pattern>/PS
    and <$result>/RS, and for every dollar-sign-identifier <D>/IDS in
    <$result>/RS, ...

      (Rule <$pattern>/PS <$result>/RS)

    ... defines an infinite set of rules, Rules, where if a rule (Rule
    <actual-pattern>/APS <actual-result>/ARS) is a member of Rules,
    then 

then if <D>/IDS is in <$pattern>/PS, then
    for every term <U>/US, let <$result-non-dollar>/RS be <$result>/RS
    except that all occurrences of <D>/IDS have been replaced with
    <U>/US+{APP}, and let <$pattern-non-dollar>/PS be <$pattern>/PS
    except that all occurrences of <D>/IDS have been replaced with
    <U>/US, where APP is a unique scope called the 'rule application
    scope'.

Then for
    every dollar-sign-identifier D/IDS+{A}, and every term <U>, let
    <$result->/RS ...

      (Rule <$pattern>/PS <$result>/RS)

    ... creates an infinite set of rules

  The following form creates an environment:

    (Env <rule> ...)

  if and only if (each <rule> reduces to a 'rule-series' AND every
  rule in every 'rule-series' are pairwise-deterministic). For any
  terms <pattern>/PS and <result>/RS, 

    (Rule <pattern>/PS <result>/RS+$)

  creates a rule-series, which is a fixed-point, which is to say that
  it is a 'value', i.e., something that can be the result of a
  program. Note that while <pattern> does not get any new scopes,
  <result> does: a unique 'pattern application scope'.

  If neither <pattern> nor <result> contain a dollar-sign-identifier,
  (e.g., $foo, $blahblahblah, $etc), then the rule-series has only one
  element: a single rule. For example,

    (Rule (x y z) (y z x))
    ; annotated with scopes below
    (Rule (x/XS y/YS z/ZS)/PS (y/YS z/ZS x/XS)/RS)

  is a single rule. It is applicable to an infinite set of terms:

    (x y z)
    ; annotated with scopes below
    (x/XS+? y/YS+? z/ZS+?)/PS+?

  ... where '<term>/<scope-set>+?' specifies any term identical to
  <term> whose scope-set is a non-strict superset of <scope-set>. This
  is to say that as long as the 'x', 'y', and 'z' (and the
  parentheses) come from at least as nested a scope as XS, YS, ZS, and
  PS respectively, the rule is applicable.

  In a given environment, the rule that is applied to the term is the
  one whose PS (the scope-set on the outer parentheses of the
  <pattern>) is 'closest' to the scope-set on the outer parentheses on
  the term (PS+?), where 'closest' involves a non-strict subset
  ordering of rules, from the one with the least elements of PS to the
  most elements. The one with the most is the rule that applies. Note:
  the definition of Env requires that the rules are
  pairwise-deterministic; this rules out the case that there are two
  rules which have the same pattern but different result AND have the
  same scope sets on 'pattern'.

  If the rule-form contains at least one 'dollar-sign-identifier' then
  it specifies an infinitely-sized rule-series. For example,

    (Rule (unwrap (Some $x)) $x)

  is an abbreviation for the following infinite series of rules:

    (Rule (unwrap (Some 0)) 0)
    (Rule (unwrap (Some 1)) 1)
    ....
    (Rule (unwrap (Some 99999999572)) 99999999572)
    ....
    (Rule (unwrap
           (Some (((((((("Hello, world!"))))) "Goodbye, world!")))))
          (((((((("Hello, world!"))))) "Goodbye, world!"))))
    ....
    (Rule (unwrap (Some undefined))
    .... etc. .....

  That rule matches any term that is placed in the position of $x, as
  long as all parts of that term have scope-sets that are non-strict
  supersets of

Definition [only-in-this-order]:

  For our purposes here, <rule>/PS/RS is a term that reduces to a rule
  whose pattern scope is PS and whose result scope is RS. The
  following term:

    (only-in-this-order <rule> ...+)

  reduces to an environment containing <rule>/

    (let [y 10]
      (let [(id y) y]
        (id y))) --> 10

    (let [y 10]
      (let [(id x) y]
        (id x))) --> 10

    (let [y 10]
      (let [(id x) y]
        (id y))) --> ERROR, no reduction for (id y).

    (let [y 10]
      (let [(id $x) y])
        (id z)) --> 10

    (let [y 10]
      (let [(id $x) (+ 1 x)]
        (id y))) --> 11

    (let [y 10]
      (let [(id $x) (+ 1 x)]
        (id z))) --> ERROR, no reduction for (+ 1 z).

    (let [(x y) 10]
      ((let x) (let y)))
    --> ((let x) (let y))
    --> (x (let y))
    --> (x y)
    --> 10

    (let [(x y) 10]
      ((let [z y] x) z))
    --> ((let [z y] x) z)
    --> (x z) --> ERROR, no reduction for (x z)


      ; io.lang

      (let [io:run
            (Env
             (freeze-pattern
              [(run (IO $x)) $x])
             (freeze-pattern
              [(run (IO $first $others ...+))
               (sequence $first
                         (IO $others ...)
                         undefined)]))]
           [io:println
            (Env
             (freeze-result
              [(println $x)
               (IO (builtins.impure.println $x))]))]
        (+ io:run io:println)

      ; now, let's uses these:

        main = (run (println "Hello, world!"))
        -->
        (let [side-effects (run (println "Hello, world!"))]
          (sequence side-effects 0 1))
        -->
        (sequence side-effects 0 1)
        -->
        (sequence (run (println "Hello, world!")) 0 1)
        --> ; Hello, world! is printed
        0

      ; but since the pattern of io:run is frozen, we can't use it in
      ; a nested scope:

        main = (let [y (run read-line)]
                    [z (run read-line)]
                 (+ y z))

Definition [freeze-at-or-below]: (freeze-at-or-below <T>/TS (Rule
$pattern/PS $result)), reduces to a rule whose pattern only matches
terms whose scope-set is a non-strict superset of PS AND a non-strict
subset of TS.

  For example, assume we are in an environment with the following
  rules:

    (freeze-at-or-below IO (Rule (run IO $x)
                                 (run:unsafe IO $x)))
    (Rule (run:unsafe IO (IO $x)) $x)
    (Rule (run:unsafe IO (IO $first $rest ...+))
          (sequence $first (run:unsafe IO $rest ...)))

  Then ...

    main = (perform-IO (bind read-line print-line))
    -->
    (sequence (unsafe-perform-IO (bind read-line print-line))
    -->
    (sequence (unsafe-perform-IO (bind read-line print-line)) 0 1)
    -->
    (sequence (unsafe-perform-IO (bind read-line print-line)) 0 1)
    --> ; "Hello, world!\n" added to stdin
    (sequence
     (unsafe-perform-IO (bind (IO "Hello, world!") print-line)) 0 1)
    --> 
    (sequence (unsafe-perform-IO (print-line "Hello, world!")) 0 1)
    -->
    (sequence (unsafe-perform-IO (IO ())) 0 1)
    -->
    (sequence () 0 1)

  But ...

    main = (perform-IO (println (sneaky-id "Hello, world!")))
    (def (sneaky-id $x)
      (sequence (perform-IO (print-line "Surprise!"))
                $x
                undefined))
    -->
    (letrec [(sneaky-id $x)
             (sequence (perform-IO (print-line "Surprise!"))
                       $x
                       undefined)]
      (sequence
       (perform-IO (println (sneaky-id "Hello, world!")))
       0
       1))
    (sequence
     (perform-IO (println (sneaky-id "Hello, world!")))
     (letrec [sneaky)         
     )
Definition [freeze-at-or-above]: (freeze-at-or-above <T>/)

Definition [let]:

  ; In environment E with next scope S,
  (let [<pattern>/SP <result>/SR]
    <body>/SB)
  --> <body>/SB+{S} ; In environment E extended with (Rule
                    ; <pattern>/SP+{S} <result>/SR) but only if the
                    ; new environment is defined, i.e., only the new
                    ; rule is pairwise-deterministic with the rules
                    ; of E.

  'let' and 'letrec' can be used to create 'containers' which can't be
  unwrapped, except by special privileged code. For example, consider
  the following term which defines '(new Secure <v>)', which 

    (export s:new s:bind)

    (def s:new
      (Rule (new Secure $v)
      
        ; Notice that the 'Secure' in the pattern of this rule above
        ; is the SAME 'Secure' as the 'Secure' in the top-level
        ; environment. This is not the case with
        ; 'Secure:secret-scope', as we will learn below:
      
        (Secure:secret-scope $v)))

    (def s:bind
      (Rule (bind (Secure:secret-scope $v) $f)
        ($f $v)))

    (def Secure:secret-scope

      ; Create a fixed-point term, 'inner-scope', that has an extra,
      ; unique scope on it (because it is defined inside of a
      ; 'letrec'). We could have tried to define 'inner-scope' inside
      ; of a 'let', and this would indeed put a new, unique, scope on
      ; 'inner-scope', but because that new unique scope wouldn't be
      ; applied to the RHS of '[inner-scope inner-scope]', the body of
      ; the 'let' would reduce to the RHS 'inner-scope' (e.g., the
      ; 'inner-scope' in the top-level environment. But if that were
      ; the case we would be able to pattern match on it in code that
      ; was run in the environment that this library reduces to, hence
      ; the need for 'letrec'). Why can't we match on the 'letrec'
      ; version? Because a rule's pattern only matches if the
      ; pattern's scope-set is a non-strict subset of the term's
      ; scope-set. Since no rule exists that reduces to THIS
      ; 'inner-scope' in the environment that this library reduces to,
      ; there is no way to get THIS 'Secure:secret-scope' in other
      ; code. This means that there is no way to reference
      ; 'inner-scope' with the special scope from the 'letrec' from
      ; anywhere else other than in this library. Rules defined
      ; outside of this library CAN, of course, match on a DIFFERENT
      ; 'Secure:secret-scope', but it wouldn't be THIS
      ; 'Secure:secret-scope'. Again, to be clear, the reason this
      ; works is because of lexical scope. There's nothing fancy
      ; happening here---just a clever (?) use of scope-sets.

      (letrec [inner-scope inner-scope]
        inner-scope))

  The reduction of the above term (see the definition of 'begin' for
  more information about how 'def' works) would be the following:

    (letrec [Secure (let [Secure-impl unique-scope]
                      Secure-impl)]
      (attempt-to-leak secret))

Definition of [letrec]: Exactly the same as [let] except that the
reduction has <result>/RS+{S} instead of <result>/RS. This allows
<result> to refer to terms in <pattern>.

  Why both 'let' and 'letrec'? Because I want both of the following
  programs to work:

    (let [x 10]
      (let [x x]
        x))
    --> 10 ; OK: 10 is a fixed-point
    
    (let [x 10]
      (letrec [x x]
        x))
    --> x ; OK: x is a fixed-point

  More specifically, we need to be able to define terms like (Some $x)
  as fixed-points. You need letrec to do this:

    (let [(Some 10) (Some 10)]
      (Some 10))
    --> (Some 10)
    --> ERROR! No rule to re-write (Some x), but (Some x) is not a
        fixed-point.

    ; This is because the (Some 10) on the RHS does not have the scope
    ; that was added to the LHS and the body of the let.

  ... but we also want to be able to shadow rules, so 'let' is
  necessary.

Definition of [cache-in-store]: (cache-in-store $) ... TODO!

Definition of [begin]: If there does not exist a rule in the
environment whose pattern matches (begin/{} $ ...) (e.g., a rule that
begins with the symbol 'begin' in the top-level scope and matches
zero-or-more subterms (whatever they may be), then the following two
rules are defined in the environment:


    Definition of [begin:program]:

      (Rule$ (begin main = $side-effects
                    (def $pattern $result) ...)
             (letrec [$pattern $result] ...
                     [side-effects (run IO $side-effects)]
               (sequence side-effects 0 1)))

      (Rule (begin main = side-effects
                   (def side-effects get-line))
            (letrec [side-effects get-line]
                    []))

      main = side-effects
      (def side-effects get-line)
      -->
      (begin main = side-effects
             (def side-effects get-line))
      -->
      (letrec [side-effects get-line]
              [side-effects (run IO side-effects)]
        (sequence side-effects 0 1))
      --> ERROR! NONDETERMINISTIC RULES TO REWRITE 'side-effects'!

    This is why we need the 'rule-application-scope' (call it {b} for
    'begin' here, and call the scope that letrec adds {lr}):
    
      main/{} =/{} side-effects/{}
      (def/{} side-effects/{} get-line/{})/{}
      --> ; this transformation isn't a rule, the 'begin' was always
          ; 'implicitly' there, so there's no rule application scope
          ; added in this step.
      (begin/{} main/{} =/{} side-effects/{}
                (def/{} side-effects/{} get-line/{})/{})/{}
      -->
      (letrec/{} [side-effects/{b,lr} get-line/{b,lr}]/{}
                 [side-effects/{lr} (run/{lr} IO/{lr} side-effects/{b,lr})/{lr}]/{}
        (sequence/{lr} side-effects/{lr} 0/{lr} 1/{lr})/{lr})/{}
      -->
      (sequence/{lr} side-effects/{lr} 0/{lr} 1/{lr})/{lr}
      -->
      (sequence/{lr} (run/{lr} IO/{lr} side-effects/{b,lr})/{lr}
                     0 1)
      -->
      (sequence/{lr} (run/{lr} IO/{lr} get-line/{b,lr}) 0 1)
      --> ; assume rule [get-line/{} (IO/{} builtins.get-line/{})/{}]/{} exists.
          ; Call its rule-application-scope 'g'.
      (sequence/{lr} (run/{lr} ))

;;;;;

      main = 

      (Rule (begin main = $side-effects
                   (def $pattern $result) ...)          
            (sequence $side-effects
                      (letrec [$pattern $result] ... 0)
                      1))
   
    Definition of [begin:library]:
    
      (Rule (begin (export $rule ...)
                   (def $pattern $result) ...)
            (let [$pattern $result] ...
                 [exports (Env $rule ...)]
              (cache-in-store exports)))


  
  The language environment, when running code, wraps the entire file
  in (begin ....). This 'default' implementation of 'begin' just
  reduces boilerplate:
  
    ; my-file.lang
    
    (factorial 10)
  
    (def (factorial $n) (factorial $n 1))
    (def (factorial $n $acc)
      (if (= $n 0)
          acc
  	(factorial (- $n 1)
  	           (* $n $acc))))
  
  This would get compiled as:
  
    (letrec [(factorial $n) (factorial $n 1)]
            [(factorial $n $acc)
             (if (= $n 0)
                 acc
                  (factorial (- $n 1)
                             (* $n $acc)))]
      (factorial 10))
  
  Which avoids the need to explicitly write everything in a 'letrec'.
  
  And if you wanted to implement your own way of restructuring programs,
  you could simply write a new (Rule (begin ....) ....) in the top-level
  scope and supply it in every environment in which you want to run
  code.
  
  'begin' is kind of like a blending of '#%module-begin' and 'begin0' in
  racket.
  
  Note: This 'default begin' is still available in nested scopes, so if
  you wanted to write 'def' inside of a 'let', you could do so:
  
    (let [food "pizza"]
      (begin (make-crazy food)
        (def (make-crazy $food)
          (make-crazier (+ "ice cream" " " $food)))
        (def (make-crazier $food)
          (+ "chocolate covered" " " $food))))
    -->
    (begin (make-crazy food)
      (def (make-crazy $food)
        (make-crazier (+ "ice cream" " " $food)))
      (def (make-crazier $food)
        (+ "chocolate covered" " " $food)))
    -->
    (letrec [(make-crazy $food)
             (make-crazier (+ "ice cream" " " $food))]
            [(make-crazier $food)
             (+ "chocolate covered" " " $food)]
      (make-crazy food))
    -->
    (make-crazy food)
    -->
    (make-crazier (+ "ice cream" " " food))
    -->
    (+ "chocolate covered"
       (+ "ice cream" " " food))
    -->
    (+ "chocolate covered" " "
       (+ "ice cream" " " "pizza"))
    -->
    (+ "chocolate covered" " " "ice cream pizza")
    -->
    "chocolate covered ice cream pizza" ; OK: reached a fixed-point.

Definition of [undefined]: There exists a term, 'undefined', which is
not a fixed-point and does not reduce to a fixed-point.

Definition of [unsequence]: (unsequence <reduce-me> <if-successful>
<if-fails>) is defined as <if-successful> IF <reduce-me> CAN BE
reduced to a fixed-point. If <reduce-me> reduces to a term Q to which
there are no available rules for rewriting Q, the 'unsequence' form is
defined as <if-fails>.

  IMPORTANT! WARNING! The order of reduction of <reduce-me>,
  <if-successful>, and <if-fails> is not specified. An implementation
  could, potentially, try to reduce them all in parallel. To sequence
  reductions that have side effects (which may be provided by an
  implementation) use 'sequence'.

Definition of [sequence]: (sequence <reduce-me> <if-successful>
<if-fails>) is defined as <if-successful> WHEN <reduce-me> IS reduced
to a fixed-point. If <reduce-me> reduces to a term Q to which there
are no available rules for rewriting Q, the 'sequence' form is defined
as <if-fails>.

  Note: the reduction order is defined as follows.

    1. Attempt to reduce <reduce-me> to a fixed-point.

    2. If (1) worked, reduce to <if-successful>.

    3. If (1) failed, reduce to <if-fails>.

  It is defined that AT MOST ONE of <if-successful> OR <if-fails> will
  be reduced (any amount). (AT MOST ONE because the reduction of
  <reduce-me> may never halt).

    (begin (reduce-in-order (print document.txt-contents)
                            (delete document.txt-filename))
      (def (reduce-in-order $term1 $term2)
        (sequence $term1 $term2 undefined))
      (def document.txt-contents
        (lang.stdlib.impure.read-file document.txt-filename))
      (def (delete $file)
        (lang.stdlib.impure.delete-file $file))
      (def document.txt-filename "document.txt"))
     
    (letrec [doc (lang.stdlib.impure.read-file "document.txt")]
         [print-doc-content
      (sequence
       doc
       (begin print&delete
         (def print&delete
           (sequence
            (builtins.stdlib.impure.print doc)
             (builtins.stdlib.impure.delete-file "document.txt")
             undefined)))
       undefined))
    -->
    (sequence
     doc
     (begin print&delete
       (def print&delete
         (sequence (builtins.stdlib.impure.print doc)
                   (builtins.stdlib.impure.delete-file "document.txt")
                   undefined)))
     undefined)
    -->
    (sequence
     <document-contents>
     (begin print&delete
       (def print&delete
         (sequence (builtins.stdlib.impure.print <document-contents>)
                   (builtins.stdlib.impure.delete-file "document.txt")
                   undefined)))
     undefined)

FIXME! remove?

 ;;; Definitions of [fence-accept] [fence-release]: (fence-release <T>)
 ;;; reduces to <T> (it is the identity function). (fence-accept <T>)
 ;;; reduces to <T> if and only if (fence-release <T>) has already been
 ;;; reduced to a fixed-point. If (fence-release <T>) reduces to a term Q
 ;;; where there are no rules for rewriting Q, (fence-accept <T>) is
 ;;; defined as [undefined].
 ;;; 
 ;;;    This is useful for ordering the reduction of terms that have side
 ;;;    effects. Here's an example of using fences to do the following in
 ;;;    this order: (1) read a file; (2) print its contents and delete
 ;;;    it. Note that the example does not specify the order of printing
 ;;;    and deleting, just that it will have read the file before it does
 ;;;    either of those things.
 ;;; 
 ;;;    Also, for the purposes here, assume that '(builtins.stdlib.impure.*
 ;;;    ....)' forms reduce to fixed-points.
 ;;; 
 ;;;    (letrec [doc (lang.stdlib.impure.read-file "document.txt")]
 ;;;            [perform-read (fence-accept doc)]
 ;;;            [doc-contents (fence-release doc)]
 ;;;      (seq perform-read
 ;;;           (let [print&delete
 ;;;                 (seq (builtins.stdlib.impure.print doc-contents)
 ;;;                      (builtins.stdlib.impure.delete-file
 ;;;                       "document.txt")
 ;;;                      undefined)]
 ;;;             print&delete)
 ;;;           undefined))
 ;;;    -->
 ;;;    (seq perform-read
 ;;;         (let [print&delete
 ;;;               (seq (builtins.stdlib.impure.print doc-contents)
 ;;;                    (builtins.stdlib.impure.delete-file
 ;;;                     "document.txt")
 ;;;                    undefined)]
 ;;;           print&delete)
 ;;;         undefined)
 ;;; 
 ;;;    From this point, there are many possible ways that reduction can
 ;;;    occur. I will only consider the 'evil demon' implementation of
 ;;;    'seq' which tries to reduce itself in a way as to attempt to cause
 ;;;    as many concurrency errors as possible. In this case, I'll make it
 ;;;    reduce its second argument as far as it can, and only then reduce
 ;;;    its first argument.
 ;;; 
 ;;;    -->
 ;;;    (seq perform-read
 ;;;         print&delete
 ;;;         undefined)
 ;;;    -->
 ;;;    (seq perform-read
 ;;;         (seq (builtins.stdlib.impure.print doc-contents)
 ;;;              (builtins.stdlib.impure.delete-file
 ;;;               "document.txt")
 ;;;              undefined)
 ;;;         undefined)
 ;;;    -->
 ;;; 
 ;;; FIXME! move this after 'noreduce' and describe why it needs
 ;;; 'noreduce'. Definition of [freeze-pattern-scopes]:
 ;;; (freeze-pattern-scopes <R>) is defined if <R> reduces to a rule and
 ;;; the following condition holds: the scope-set of the pattern of <R> is
 ;;; a non-strict superset of the scope-set of the result of <R>. In other
 ;;; words, (freeze-pattern-scopes <R>) is not available in more-nested
 ;;; scopes.
 ;;; 
 ;;;   This is useful for implementing a Haskell-style IO Monad. Here we
 ;;;   want to write code that executes the IO Monad, but we only want this
 ;;;   to be done at the top-level (i.e., we don't want to allow reducing
 ;;;   the term (IO <X>) in a nested scope). For example, the following
 ;;;   code could be an implementation of 'begin' that would make a program
 ;;;   run in an environment containing the rule not able to use 'begin' in
 ;;;   a nested scope (to perform an IO action in a seemingly-pure
 ;;;   context):
 ;;; 
 ;;;   (freeze-pattern-scopes
 ;;;    (Rule (begin $main (def $pattern $result) ...)
 ;;;          (letrec [$pattern $result] ...
 ;;;            ; pretend that there exists a rule to re-write the
 ;;;            ; unsafe-perform-IO form to a series of 'sequence' forms.
 ;;;            (noreduce (unsafe-perform-IO $main)))))
 ;;; 
 ;;;   In an environment containing the previous rule, the following
 ;;;   reduction could occur:
 ;;; 
 ;;;   (let [doc (lang.stdlib.pure.read-file "document.txt")]
 ;;;     ; it would make sense here that (lang.stdlib.pure.read-file ....)
 ;;;     ; reduces to a fixed-point (IO <X>).
 ;;;     (begin doc))
 ;;;   --> (begin doc)
 ;;;   --> ERROR! No rules for rewriting '(begin doc)'. The closest is
 ;;;       '(begin $result (def $pattern $result) ...)', but that rule is
 ;;;       FROZEN as to not be available in more-nested scopes.
 ;;; 
 ;;; Definition of [noreduce]: The following rule exists in the top-level
 ;;; environment:
 ;;; 
 ;;;     (Rule (noreduce $) undefined)
 ;;; 
 ;;;   ... which is technically speaking an infinite series of rules---one
 ;;;   rule for each thing you could put in '$'---which ignores all of its
 ;;;   subterms and reduces to 'undefined'.
 ;;; 
 ;;;   This is useful for implementing pure rules using impure rules. While
 ;;;   purely-functional data structures are great, they can't do
 ;;;   everything. Sometimes the need for speed and space requires that we
 ;;;   use impurity. But it IS possible to write a rule that (1) doesn't
 ;;;   mutate its arguments, (2) always returns the same result for the
 ;;;   given arguments, and (3) uses mutation internally to do some
 ;;;   computation in a way that would be too slow or too space intensive
 ;;;   using purely-functional data structures. I think it would be
 ;;;   reasonable to call this rule 'pure', as the impurity inside of it is
 ;;;   merely an implementation detail of the rule; no one would know
 ;;;   otherwise if it was implemented using purely-functional data
 ;;;   structures (except that they might notice it taking longer to reduce
 ;;;   or taking more memory to reduce).
 ;;; 
 ;;;     ; For example, the implementation of a standard library could
 ;;;     ; contain the following rules which allow the creation of an
 ;;;     ; 'Internally-Mutable-Vector' that can't be reduced which is just
 ;;;     ; a wrapper around an (assuming) already-defined Mutable-Vector.
 ;;; 
 ;;;       mutable-vector-env+sequence-many-env
 ;;; 
 ;;;       (def mutable-vector-env+sequence-many-env
 ;;;         (Env m:new
 ;;;              m:mutable->immutable
 ;;;              m:set!
 ;;;              m:sequence-many1
 ;;;              m:sequence-many*))
 ;;; 
 ;;;       (def m:new
 ;;;         (Rule (new Internally-Mutable-Vector $size)
 ;;;           (begin (helper Internally-Mutable-Vector)
 ;;;             (def (helper $term-with-outside-scope)
 ;;;               (let
 ;;;                 (noreduce ($term-with-outside-scope (new lang.builtins.Mutable-Vector $size))))))))
 ;;; 
 ;;;       (def m:mutable->immutable
 ;;;         (Rule (mutable->immutable
 ;;;                (noreduce (Internally-Mutable-Vector $v)))
 ;;;               (mutable->immutable $v)))
 ;;;       
 ;;;       (def m:set!
 ;;;         (Rule (Internally-Mutable-Vector (noreduce $v))
 ;;;               $index
 ;;;               $value)
 ;;;           (set! $v $index $value))
 ;;; 
 ;;;       ; the following is useful for performing a lot of set!
 ;;;       ; operations:
 ;;;       (def m:sequence-many1
 ;;;         (Rule (sequence-many $term0) $term0))
 ;;;       (def m:sequence-many*
 ;;;         (Rule (sequence-many $term0 $terms ...+)
 ;;;           (sequence $term0
 ;;;                     (sequence-many $terms ...)
 ;;;                     undefined)))
 ;;; 
 ;;;     ; If these rules were present in our environment and we attempted
 ;;;     ; to return this 'Internally-Mutable-Vector', it wouldn't work:
 ;;; 
 ;;;       (let [v (new Internally-Mutable-Vector 2)]
 ;;;         (sequence-many (set! v 0 "a")
 ;;;                        (set! v 1 "b")
 ;;;                        v)) ; here we try to return 'v'
 ;;;       -->
 ;;;       (sequence-many (set! v 0 "a")
 ;;;                      (set! v 1 "b")
 ;;;                      v)
 ;;;       -->
 ;;;       (sequence (set! v 0 "a")
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       -->
 ;;;       (sequence (set! (new Internally-Mutable-Vector 2) 0 "a")
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       -->
 ;;;       (sequence (set! (noreduce (Internally-Mutable-Vector m)) 0 "a")
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       -->
 ;;;       (sequence (set! m 0 "a")
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       -->
 ;;;       (sequence (set! (new lang.builtins.Mutable-Vector 2) 0 "a")
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       --> ; assuming that 'new' rule on lang.builtins.Mutable-Vector
 ;;;           ; returns the fixed-point mutable vector representation
 ;;;           ; '<builtin-mut-vec>':
 ;;;       (sequence (set! <builtin-mut-vec> 0 "a")
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       --> ; assuming that the 'set!' rule on '<builtin-mut-vec>'
 ;;;           ; returns '<builtin-mut-vec>' itself after setting the value
 ;;;           ; at the index in the vector:
 ;;;       (sequence <builtin-mut-vec>
 ;;;                 (sequence-many (set! v 1 "b") v)
 ;;;                 undefined)
 ;;;       -->
 ;;;       (sequence-many (set! v 1 "b") v)
 ;;;       -->
 ;;;       (sequence (set! v 1 "b")
 ;;;                 (sequence-many v)
 ;;;                 undefined)
 ;;;       -- .... -->
 ;;;       (sequence (set! <builtin-mut-vec> 1 "b")
 ;;;                 (sequence-many v)
 ;;;                 undefined)
 ;;;       -->
 ;;;       (sequence-many v)
 ;;;       -->
 ;;;       v
 ;;;       --> ; at this point, due to sequencing, the mutable vector
 ;;;           ; inside of 'v' has already long been fully reduced to a
 ;;;           ; fixed-point, even though 'v' itself has not been. I'm
 ;;;           ; writing this to explain that even though 'v' reduces to
 ;;;           ; '(new Internally-Mutable-Vector 2)', it's not the case
 ;;;           ; that this creates a 'new' vector: it is the same one that
 ;;;           ; has been being mutated this whole time.
 ;;;       (new Internally-Mutable-Vector 2)
 ;;;       -->
 ;;;       (noreduce (Internally-Mutable-Vector m))
 ;;;       --> ; ERROR: attempt to REDUCE THE IRREDUCIBLE!
 ;;; 
 ;;;     ; But can't we 'break the system' by doing this?
 ;;; 
 ;;;       (def (impure-unwrap (Internally-Mutable-Vector (noreduce $v)))
 ;;;         $v)
 ;;; 
 ;;;       (let [v (new Internally-Mutable-Vector 2)]
 ;;;         (sequence-many (set! v 0 "a")
 ;;;                        (set! v 1 "b")
 ;;;                        (impure-unwrap v)))
 ;;;       -- .... -->
 ;;;       <builtin-mut-vec>
 ;;; 
 ;;;     ; Well, of course you can. But why would you?
 ;;;    
 ;;;     ; Here we will implement an algorithm that takes an integer N as
 ;;;     ; input and returns an immutable vector of size N, after filling
 ;;;     ; it with some data. Exactly what data goes in the vector is not
 ;;;     ; specified here, but filling the vector with data should involve
 ;;;     ; lots of expensive operations that would be hard to do in a
 ;;;     ; purely-functional way.
 ;;;     
 ;;;     (Rule (pure-algorithm $arg)
 ;;;           (pure-algorithm/internal-mutation $arg))
 ;;; 
 ;;;     (def (sequence-many $term0 $term ...+)
 ;;;       (sequence $term0
 ;;;                 (sequence-many $term ...)
 ;;;                 undefined))
 ;;; 
 ;;;     (def (pure-algorithm/internal-mutation $arg)
 ;;;       (let [v (new mutable-vector:internal $arg)]
 ;;;         (sequence v
 ;;;                   (begin (mutable-vector:internal->immutable-vector v)
 ;;;                     ....))))
 ;;; 
